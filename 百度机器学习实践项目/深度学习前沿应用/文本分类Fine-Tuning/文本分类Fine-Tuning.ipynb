{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T10:03:01.360512Z",
     "iopub.status.busy": "2022-07-25T10:03:01.360285Z",
     "iopub.status.idle": "2022-07-25T10:03:03.267038Z",
     "shell.execute_reply": "2022-07-25T10:03:03.265879Z",
     "shell.execute_reply.started": "2022-07-25T10:03:01.360488Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "import paddlenlp as ppnlp\n",
    "from paddlenlp.data import Stack,Pad,Tuple\n",
    "import paddle.nn.functional as F\n",
    "import numpy as np\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T10:03:03.270230Z",
     "iopub.status.busy": "2022-07-25T10:03:03.269560Z",
     "iopub.status.idle": "2022-07-25T10:03:03.321200Z",
     "shell.execute_reply": "2022-07-25T10:03:03.320121Z",
     "shell.execute_reply.started": "2022-07-25T10:03:03.270198Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds,dev_ds,test_ds=ppnlp.datasets.ChnSentiCorp.get_datasets(['train','dev','test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T10:03:03.323041Z",
     "iopub.status.busy": "2022-07-25T10:03:03.322467Z",
     "iopub.status.idle": "2022-07-25T10:03:03.327245Z",
     "shell.execute_reply": "2022-07-25T10:03:03.326440Z",
     "shell.execute_reply.started": "2022-07-25T10:03:03.323012Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_list=train_ds.get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T10:03:03.329503Z",
     "iopub.status.busy": "2022-07-25T10:03:03.328612Z",
     "iopub.status.idle": "2022-07-25T10:03:03.339825Z",
     "shell.execute_reply": "2022-07-25T10:03:03.338967Z",
     "shell.execute_reply.started": "2022-07-25T10:03:03.329463Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T10:03:03.341825Z",
     "iopub.status.busy": "2022-07-25T10:03:03.341140Z",
     "iopub.status.idle": "2022-07-25T10:03:03.346722Z",
     "shell.execute_reply": "2022-07-25T10:03:03.345885Z",
     "shell.execute_reply.started": "2022-07-25T10:03:03.341801Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['這間酒店環境和服務態度亦算不錯,但房間空間太小~~不宣容納太大件行李~~且房間格調還可以~~ 中餐廳的廣東點心不太好吃~~要改善之~~~~但算價錢平宜~~可接受~~ 西餐廳格調都很好~~但吃的味道一般且令人等得太耐了~~要改善之~~',\n",
       "  '1'],\n",
       " ['<荐书> 推荐所有喜欢<红楼>的红迷们一定要收藏这本书,要知道当年我听说这本书的时候花很长时间去图书馆找和借都没能如愿,所以这次一看到当当有,马上买了,红迷们也要记得备货哦!',\n",
       "  '1'],\n",
       " ['商品的不足暂时还没发现，京东的订单处理速度实在.......周二就打包完成，周五才发货...', '0'],\n",
       " ['２００１年来福州就住在这里，这次感觉房间就了点，温泉水还是有的．总的来说很满意．早餐简单了些．', '1'],\n",
       " ['不错的上网本，外形很漂亮，操作系统应该是个很大的 卖点，电池还可以。整体上讲，作为一个上网本的定位，还是不错的。', '1'],\n",
       " ['房间地毯太脏，临近火车站十分吵闹，还好是双层玻璃。服务一般，酒店门口的TAXI讲是酒店的长期合作关系，每月要交费给酒店。从酒店到机场讲得是打表147元，到了后非要200元，可能被小宰30-40元。',\n",
       "  '0'],\n",
       " ['本来想没事的时候翻翻，可惜看不下去，还是和张没法比，他的书能畅销大部分还是受张的影响，对这个男人实在是没好感，不知道怎么买的，后悔', '0'],\n",
       " ['这台机外观十分好,本人喜欢,性能不错,是LED显示屏,无线网卡是: 5100AGN 无线网卡,如果装的是一条2G 800MHZ的内存就无敌了,本本发热很小,总体来说是十分值得买的,前提是这台机是4299买的.',\n",
       "  '1'],\n",
       " ['全键盘带数字键的 显卡足够强大.N卡相对A卡,个人偏向N卡 GHOST XP很容易.除了指纹识别外.所有驱动都能装齐全了,指纹识别,非要在XP下使用的朋友,可以用替代驱动.贡献下驱动地址: http://dlsvr01.asus.com/pub/ASUS/nb/F9Dc/Fingerprints_XP_080530.zip (华硕官方地址,放心下吧)',\n",
       "  '1'],\n",
       " ['做工很漂亮，老婆很喜欢。T4200足够了，性价比不错的机器。测试了一下很安逸。今天晚上准备TWOW溜达圈，再看看整机表现如何！', '1']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_ds[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T10:03:03.348193Z",
     "iopub.status.busy": "2022-07-25T10:03:03.347955Z",
     "iopub.status.idle": "2022-07-25T10:03:03.369883Z",
     "shell.execute_reply": "2022-07-25T10:03:03.369010Z",
     "shell.execute_reply.started": "2022-07-25T10:03:03.348173Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-07-25 18:03:03,349] [    INFO] - Found /home/aistudio/.paddlenlp/models/bert-base-chinese/bert-base-chinese-vocab.txt\n"
     ]
    }
   ],
   "source": [
    "tokenizer=ppnlp.transformers.BertTokenizer.from_pretrained(\"bert-base-chinese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T10:03:03.371473Z",
     "iopub.status.busy": "2022-07-25T10:03:03.371068Z",
     "iopub.status.idle": "2022-07-25T10:03:03.377818Z",
     "shell.execute_reply": "2022-07-25T10:03:03.376991Z",
     "shell.execute_reply.started": "2022-07-25T10:03:03.371449Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_example(example,tokenizer,label_list,max_seq_length=256,is_test=False):\n",
    "    if is_test:\n",
    "        text=example\n",
    "    else:\n",
    "        text,label=example\n",
    "    \n",
    "    encoded_inputs=tokenizer.encode(text=text,max_seq_len=max_seq_length)\n",
    "    input_ids=encoded_inputs['input_ids']\n",
    "    segment_ids=encoded_inputs[\"token_type_ids\"]\n",
    "\n",
    "    if not is_test:\n",
    "        label_map={}\n",
    "        for i,l in enumerate(label_list):\n",
    "            label_map[l]=i\n",
    "        label=label_map[label]\n",
    "        label=np.array([label],dtype='int64')\n",
    "        return input_ids,segment_ids,label\n",
    "    else:\n",
    "        return input_ids,segment_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T10:03:03.379098Z",
     "iopub.status.busy": "2022-07-25T10:03:03.378849Z",
     "iopub.status.idle": "2022-07-25T10:03:03.385265Z",
     "shell.execute_reply": "2022-07-25T10:03:03.384376Z",
     "shell.execute_reply.started": "2022-07-25T10:03:03.379077Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataloader(dataset,trans_fn=None,mode='train',batch_size=1,use_gpu=False,pad_token_id=0,batchify_fn=None):\n",
    "    if trans_fn:\n",
    "        dataset=dataset.apply(trans_fn,lazy=True)\n",
    "    if mode=='train' and use_gpu:\n",
    "        sampler=paddle.io.DistributedBatchSampler(dataset=dataset,batch_size=batch_size,shuffle=True)\n",
    "    else:\n",
    "        shuffle=True if mode=='train' else False\n",
    "        sampler=paddle.io.BatchSampler(dataset=dataset,batch_size=batch_size,shuffle=shuffle)\n",
    "\n",
    "    dataloader=paddle.io.DataLoader(dataset,batch_sampler=sampler,return_list=True,collate_fn=batchify_fn)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T10:03:03.386739Z",
     "iopub.status.busy": "2022-07-25T10:03:03.386380Z",
     "iopub.status.idle": "2022-07-25T10:03:03.391437Z",
     "shell.execute_reply": "2022-07-25T10:03:03.390614Z",
     "shell.execute_reply.started": "2022-07-25T10:03:03.386708Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "trans_fn=partial(convert_example,tokenizer=tokenizer,label_list=label_list,max_seq_length=128,is_test=False)\n",
    "batchify_fn=lambda samples,fn=Tuple(Pad(axis=0,pad_val=tokenizer.pad_token_id),Pad(axis=0,pad_val=tokenizer.pad_token_id),Stack(dtype='int64')):[data for data in fn(samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T10:03:03.392789Z",
     "iopub.status.busy": "2022-07-25T10:03:03.392450Z",
     "iopub.status.idle": "2022-07-25T10:03:03.397537Z",
     "shell.execute_reply": "2022-07-25T10:03:03.396678Z",
     "shell.execute_reply.started": "2022-07-25T10:03:03.392762Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_loader=create_dataloader(train_ds,mode='train',batch_size=64,batchify_fn=batchify_fn,trans_fn=trans_fn)\n",
    "dev_loader=create_dataloader(dev_ds,mode='dev',batch_size=64,batchify_fn=batchify_fn,trans_fn=trans_fn)\n",
    "test_loader=create_dataloader(test_ds,mode='test',batch_size=64,batchify_fn=batchify_fn,trans_fn=trans_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T10:03:03.400886Z",
     "iopub.status.busy": "2022-07-25T10:03:03.400575Z",
     "iopub.status.idle": "2022-07-25T10:03:09.276783Z",
     "shell.execute_reply": "2022-07-25T10:03:09.275723Z",
     "shell.execute_reply.started": "2022-07-25T10:03:03.400864Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-07-25 18:03:03,402] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/bert-base-chinese/bert-base-chinese.pdparams\n",
      "W0725 18:03:03.405943  1346 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 10.1\n",
      "W0725 18:03:03.410030  1346 gpu_resources.cc:91] device: 0, cuDNN Version: 7.6.\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1492: UserWarning: Skip loading for classifier.weight. classifier.weight is not found in the provided dict.\n",
      "  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1492: UserWarning: Skip loading for classifier.bias. classifier.bias is not found in the provided dict.\n",
      "  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\n"
     ]
    }
   ],
   "source": [
    "model=ppnlp.transformers.BertForSequenceClassification.from_pretrained('bert-base-chinese',num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T10:03:09.278726Z",
     "iopub.status.busy": "2022-07-25T10:03:09.278423Z",
     "iopub.status.idle": "2022-07-25T10:03:09.283285Z",
     "shell.execute_reply": "2022-07-25T10:03:09.282538Z",
     "shell.execute_reply.started": "2022-07-25T10:03:09.278700Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning_rate=1e-5\n",
    "epochs=8\n",
    "warmup_proption=0.1\n",
    "weight_decay=0.01\n",
    "\n",
    "num_training_steps=len(train_loader)*epochs\n",
    "num_warmup_steps=int(warmup_proption*num_training_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T10:03:09.284609Z",
     "iopub.status.busy": "2022-07-25T10:03:09.284276Z",
     "iopub.status.idle": "2022-07-25T10:03:09.289676Z",
     "shell.execute_reply": "2022-07-25T10:03:09.288997Z",
     "shell.execute_reply.started": "2022-07-25T10:03:09.284586Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_lr_factor(current_step):\n",
    "    if current_step<num_warmup_steps:\n",
    "        return float(current_step)/float(max(1,num_warmup_steps))\n",
    "    else:\n",
    "        return max(0.0,float(num_training_steps-current_step)/float(max(1,num_training_steps-num_warmup_steps)))\n",
    "\n",
    "lr_scheduler=paddle.optimizer.lr.LambdaDecay(learning_rate,lr_lambda=lambda current_step:get_lr_factor(current_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T10:03:09.291025Z",
     "iopub.status.busy": "2022-07-25T10:03:09.290556Z",
     "iopub.status.idle": "2022-07-25T10:03:09.296167Z",
     "shell.execute_reply": "2022-07-25T10:03:09.295446Z",
     "shell.execute_reply.started": "2022-07-25T10:03:09.291001Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer=paddle.optimizer.AdamW(\n",
    "    learning_rate=lr_scheduler,\n",
    "    parameters=model.parameters(),\n",
    "    weight_decay=weight_decay,\n",
    "    apply_decay_param_fun=lambda x : x in [\n",
    "        p.name for n,p in model.named_parameters() if not any(nd in n for nd in ['bias','norm'])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T10:03:09.297589Z",
     "iopub.status.busy": "2022-07-25T10:03:09.297104Z",
     "iopub.status.idle": "2022-07-25T10:03:09.301237Z",
     "shell.execute_reply": "2022-07-25T10:03:09.300496Z",
     "shell.execute_reply.started": "2022-07-25T10:03:09.297565Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion=paddle.nn.loss.CrossEntropyLoss()\n",
    "metric=paddle.metric.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T10:03:09.302639Z",
     "iopub.status.busy": "2022-07-25T10:03:09.302217Z",
     "iopub.status.idle": "2022-07-25T10:03:09.307799Z",
     "shell.execute_reply": "2022-07-25T10:03:09.307089Z",
     "shell.execute_reply.started": "2022-07-25T10:03:09.302617Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model,criterion,metric,data_loader):\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "    losses=[]\n",
    "    for batch in data_loader:\n",
    "        input_ids,segment_ids,labels=batch\n",
    "        logits=model(input_ids,segment_ids)\n",
    "        loss=criterion(logits,labels)\n",
    "        losses.append(loss.numpy())\n",
    "        correct=metric.compute(logits,labels)\n",
    "        metric.update(correct)\n",
    "    accu=metric.accumulate()\n",
    "    print(f'eval loss:{np.mean(losses)},accu:{accu}')\n",
    "    model.train()\n",
    "    metric.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T10:03:09.309098Z",
     "iopub.status.busy": "2022-07-25T10:03:09.308678Z",
     "iopub.status.idle": "2022-07-25T10:11:45.782147Z",
     "shell.execute_reply": "2022-07-25T10:11:45.781046Z",
     "shell.execute_reply.started": "2022-07-25T10:03:09.309074Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step:50,epoch:1,batch:49,loss:0.5385169982910156,acc:0.6021875\n",
      "global step:100,epoch:1,batch:99,loss:0.2923926115036011,acc:0.74328125\n",
      "global step:150,epoch:1,batch:149,loss:0.3264506459236145,acc:0.795625\n",
      "eval loss:0.24134096503257751,accu:0.9083333333333333\n",
      "global step:200,epoch:2,batch:49,loss:0.29615771770477295,acc:0.929375\n",
      "global step:250,epoch:2,batch:99,loss:0.2572271227836609,acc:0.9265625\n",
      "global step:300,epoch:2,batch:149,loss:0.20216935873031616,acc:0.9296875\n",
      "eval loss:0.23167826235294342,accu:0.9191666666666667\n",
      "global step:350,epoch:3,batch:49,loss:0.16878321766853333,acc:0.9434375\n",
      "global step:400,epoch:3,batch:99,loss:0.05547510087490082,acc:0.946875\n",
      "global step:450,epoch:3,batch:149,loss:0.06831805408000946,acc:0.9509375\n",
      "eval loss:0.1992219090461731,accu:0.9366666666666666\n",
      "global step:500,epoch:4,batch:49,loss:0.22845739126205444,acc:0.970625\n",
      "global step:550,epoch:4,batch:99,loss:0.10674230754375458,acc:0.970625\n",
      "global step:600,epoch:4,batch:149,loss:0.030239656567573547,acc:0.9705208333333334\n",
      "eval loss:0.19865848124027252,accu:0.94\n",
      "global step:650,epoch:5,batch:49,loss:0.06565798074007034,acc:0.9775\n",
      "global step:700,epoch:5,batch:99,loss:0.07099664956331253,acc:0.97859375\n",
      "global step:750,epoch:5,batch:149,loss:0.06236879155039787,acc:0.9784375\n",
      "eval loss:0.20388376712799072,accu:0.9458333333333333\n",
      "global step:800,epoch:6,batch:49,loss:0.0243663489818573,acc:0.9859375\n",
      "global step:850,epoch:6,batch:99,loss:0.02075362391769886,acc:0.98609375\n",
      "global step:900,epoch:6,batch:149,loss:0.13216306269168854,acc:0.9858333333333333\n",
      "eval loss:0.20955215394496918,accu:0.9441666666666667\n",
      "global step:950,epoch:7,batch:49,loss:0.03409536927938461,acc:0.989375\n",
      "global step:1000,epoch:7,batch:99,loss:0.03278198093175888,acc:0.98828125\n",
      "global step:1050,epoch:7,batch:149,loss:0.03026096522808075,acc:0.9891666666666666\n",
      "eval loss:0.22870475053787231,accu:0.94\n",
      "global step:1100,epoch:8,batch:49,loss:0.017320647835731506,acc:0.9915625\n",
      "global step:1150,epoch:8,batch:99,loss:0.0786522701382637,acc:0.99171875\n",
      "global step:1200,epoch:8,batch:149,loss:0.11292309314012527,acc:0.9907291666666667\n",
      "eval loss:0.2244565635919571,accu:0.9408333333333333\n"
     ]
    }
   ],
   "source": [
    "#开始训练\n",
    "global_step=0\n",
    "for epoch in range(1,epochs+1):\n",
    "    for step,batch in enumerate(train_loader):\n",
    "        input_ids,segment_ids,labels=batch\n",
    "        logits=model(input_ids,segment_ids)\n",
    "        loss=criterion(logits,labels)\n",
    "        probs=F.softmax(logits,axis=1)\n",
    "        correct=metric.compute(logits,labels)\n",
    "        metric.update(correct)\n",
    "        acc=metric.accumulate()\n",
    "\n",
    "        global_step+=1\n",
    "        if global_step%50==0:\n",
    "            print(f\"global step:{global_step},epoch:{epoch},batch:{step},loss:{loss.numpy()[0]},acc:{acc}\")\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.clear_gradients()\n",
    "    evaluate(model,criterion,metric,dev_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T11:27:43.198606Z",
     "iopub.status.busy": "2022-07-25T11:27:43.197726Z",
     "iopub.status.idle": "2022-07-25T11:27:43.207697Z",
     "shell.execute_reply": "2022-07-25T11:27:43.206695Z",
     "shell.execute_reply.started": "2022-07-25T11:27:43.198559Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict(model,data,tokenizer,label_map,batch_size=1):\r\n",
    "    examples=[]\r\n",
    "    for text in data:\r\n",
    "        input_ids,segment_ids=convert_example(text,tokenizer,label_map.values(),max_seq_length=128,is_test=True)\r\n",
    "        examples.append((input_ids,segment_ids))\r\n",
    "    \r\n",
    "    batchify_fn=lambda samples,fn=Tuple(\r\n",
    "        Pad(axis=0,pad_val=tokenizer.pad_token_id),\r\n",
    "        Pad(axis=0,pad_val=tokenizer.pad_token_id)\r\n",
    "    ):fn(samples)\r\n",
    "\r\n",
    "    batches=[]\r\n",
    "    one_batch=[]\r\n",
    "\r\n",
    "    for example in examples:\r\n",
    "        one_batch.append(example)\r\n",
    "        if len(one_batch) == batch_size:\r\n",
    "            batches.append(one_batch)\r\n",
    "            one_batch=[]\r\n",
    "    \r\n",
    "    if one_batch:\r\n",
    "        batches.append(one_batch)\r\n",
    "\r\n",
    "    results=[]\r\n",
    "    model.eval()\r\n",
    "\r\n",
    "    for batch in batches:\r\n",
    "        input_ids,segment_ids=batchify_fn(batch)\r\n",
    "        input_ids=paddle.to_tensor(input_ids)\r\n",
    "        segment_ids=paddle.to_tensor(segment_ids)\r\n",
    "        logits=model(input_ids,segment_ids)\r\n",
    "        probs=F.softmax(logits,axis=1)\r\n",
    "        idx=paddle.argmax(probs,axis=1).numpy()\r\n",
    "        idx=idx.tolist()\r\n",
    "\r\n",
    "        labels=[label_map[i] for i in idx]\r\n",
    "        results.extend(labels)\r\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T11:32:18.035054Z",
     "iopub.status.busy": "2022-07-25T11:32:18.034397Z",
     "iopub.status.idle": "2022-07-25T11:32:18.076516Z",
     "shell.execute_reply": "2022-07-25T11:32:18.075772Z",
     "shell.execute_reply.started": "2022-07-25T11:32:18.035013Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测文本:暑期课满分,又加了一点\n",
      "情绪标签:负向情绪\n",
      "预测文本:你也是牛逼\n",
      "情绪标签:负向情绪\n",
      "预测文本:我去南湖了\n",
      "情绪标签:正向情绪\n",
      "预测文本:直接趟了\n",
      "情绪标签:负向情绪\n"
     ]
    }
   ],
   "source": [
    "data=['暑期课满分,又加了一点','你也是牛逼',\"我去南湖了\",\"直接趟了\"]\r\n",
    "label_map={0:'负向情绪',1:'正向情绪'}\r\n",
    "\r\n",
    "predictions=predict(model,data,tokenizer,label_map,batch_size=32)\r\n",
    "for idx,text in enumerate(data):\r\n",
    "    print(\"预测文本:{}\\n情绪标签:{}\".format(text,predictions[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
