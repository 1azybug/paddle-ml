{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-19T06:23:20.247497Z",
     "iopub.status.busy": "2022-07-19T06:23:20.246279Z",
     "iopub.status.idle": "2022-07-19T06:23:22.758118Z",
     "shell.execute_reply": "2022-07-19T06:23:22.756830Z",
     "shell.execute_reply.started": "2022-07-19T06:23:20.247456Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import MutableMapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable, Mapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sized\n"
     ]
    }
   ],
   "source": [
    "import paddle \r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt \r\n",
    "import paddle.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-19T06:23:29.728379Z",
     "iopub.status.busy": "2022-07-19T06:23:29.727755Z",
     "iopub.status.idle": "2022-07-19T06:25:18.667251Z",
     "shell.execute_reply": "2022-07-19T06:25:18.666085Z",
     "shell.execute_reply.started": "2022-07-19T06:23:29.728341Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset...\n",
      "item    34/20539 [..............................] - ETA: 43s - 2ms/item"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cache file /home/aistudio/.cache/paddle/dataset/imdb/imdb%2FaclImdb_v1.tar.gz not found, downloading https://dataset.bj.bcebos.com/imdb%2FaclImdb_v1.tar.gz \n",
      "Begin to download\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item 20539/20539 [============================>.] - ETA: 0s - 1ms/item"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Download finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading finished\n"
     ]
    }
   ],
   "source": [
    "print('loading dataset...')\r\n",
    "train_dataset=paddle.text.datasets.Imdb(mode='train')\r\n",
    "test_dataset=paddle.text.datasets.Imdb(mode='test')\r\n",
    "print('loading finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-19T06:26:46.150212Z",
     "iopub.status.busy": "2022-07-19T06:26:46.149726Z",
     "iopub.status.idle": "2022-07-19T06:26:46.155569Z",
     "shell.execute_reply": "2022-07-19T06:26:46.154631Z",
     "shell.execute_reply.started": "2022-07-19T06:26:46.150176Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_dict=train_dataset.word_idx\r\n",
    "word_dict['<pad>']=len(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-19T06:26:47.802280Z",
     "iopub.status.busy": "2022-07-19T06:26:47.800167Z",
     "iopub.status.idle": "2022-07-19T06:26:47.812462Z",
     "shell.execute_reply": "2022-07-19T06:26:47.811126Z",
     "shell.execute_reply.started": "2022-07-19T06:26:47.802214Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the:0\n",
      "and:1\n",
      "a:2\n",
      "of:3\n",
      "to:4\n",
      "...\n",
      "virtual:5143\n",
      "warriors:5144\n",
      "widely:5145\n",
      "<unk>:5146\n",
      "<pad>:5147\n",
      "total 5148 words\n"
     ]
    }
   ],
   "source": [
    "for k in list(word_dict)[:5]:\r\n",
    "    print(\"{}:{}\".format(k.decode('ASCII'),word_dict[k]))\r\n",
    "print(\"...\")\r\n",
    "for k in list(word_dict)[-5:]:\r\n",
    "    print(\"{}:{}\".format(k if isinstance(k,str) else k.decode(\"ASCII\"),word_dict[k]))\r\n",
    "print(\"total {} words\".format(len(word_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-19T06:26:49.646313Z",
     "iopub.status.busy": "2022-07-19T06:26:49.645455Z",
     "iopub.status.idle": "2022-07-19T06:26:49.666192Z",
     "shell.execute_reply": "2022-07-19T06:26:49.665046Z",
     "shell.execute_reply.started": "2022-07-19T06:26:49.646276Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence id list :\n",
      "[5146, 43, 71, 6, 1092, 14, 0, 878, 130, 151, 5146, 18, 281, 747, 0, 5146, 3, 5146, 2165, 37, 5146, 46, 5, 71, 4089, 377, 162, 46, 5, 32, 1287, 300, 35, 203, 2136, 565, 14, 2, 253, 26, 146, 61, 372, 1, 615, 5146, 5, 30, 0, 50, 3290, 6, 2148, 14, 0, 5146, 11, 17, 451, 24, 4, 127, 10, 0, 878, 130, 43, 2, 50, 5146, 751, 5146, 5, 2, 221, 3727, 6, 9, 1167, 373, 9, 5, 5146, 7, 5, 1343, 13, 2, 5146, 1, 250, 7, 98, 4270, 56, 2316, 0, 928, 11, 11, 9, 16, 5, 5146, 5146, 6, 50, 69, 27, 280, 27, 108, 1045, 0, 2633, 4177, 3180, 17, 1675, 1, 2571]\n",
      "label: 0\n",
      "--------------------------------------------------------\n",
      "sentencs :\n",
      "<unk> has much in common with the third man another <unk> film set among the <unk> of <unk> europe like <unk> there is much inventive camera work there is an innocent american who gets emotionally involved with a woman he doesnt really understand and whose <unk> is all the more striking in contrast with the <unk> br but id have to say that the third man has a more <unk> storyline <unk> is a bit disjointed in this respect perhaps this is <unk> it is presented as a <unk> and making it too coherent would spoil the effect br br this movie is <unk> <unk> in more than one sense one never sees the sun shine grim but intriguing and frightening\n",
      "label: negative\n"
     ]
    }
   ],
   "source": [
    "vocab_size=len(word_dict)+1\r\n",
    "emb_size=256\r\n",
    "seq_len=200\r\n",
    "batch_size=32\r\n",
    "epochs=2\r\n",
    "pad_id=word_dict['<pad>']\r\n",
    "classes=['negative','positive']\r\n",
    "\r\n",
    "def ids_to_str(ids):\r\n",
    "    sens=[]\r\n",
    "    for k in ids:\r\n",
    "        w=list(word_dict)[k]\r\n",
    "        sens.append(w if isinstance(w,str) else w.decode('utf-8'))\r\n",
    "    return ' '.join(sens)\r\n",
    "\r\n",
    "sent =train_dataset.docs[0]\r\n",
    "label=train_dataset.labels[0]\r\n",
    "\r\n",
    "print('sentence id list :')\r\n",
    "print(sent)\r\n",
    "print(\"label:\",label)\r\n",
    "\r\n",
    "print(\"--------------------------------------------------------\")\r\n",
    "print(\"sentencs :\")\r\n",
    "print(ids_to_str(sent))\r\n",
    "print('label:',classes[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-19T06:26:52.077006Z",
     "iopub.status.busy": "2022-07-19T06:26:52.076370Z",
     "iopub.status.idle": "2022-07-19T06:26:53.862752Z",
     "shell.execute_reply": "2022-07-19T06:26:53.861725Z",
     "shell.execute_reply.started": "2022-07-19T06:26:52.076969Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 200)\n",
      "(25000, 1)\n",
      "(25000, 200)\n",
      "(25000, 1)\n",
      "<unk> has much in common with the third man another <unk> film set among the <unk> of <unk> europe like <unk> there is much inventive camera work there is an innocent american who gets emotionally involved with a woman he doesnt really understand and whose <unk> is all the more striking in contrast with the <unk> br but id have to say that the third man has a more <unk> storyline <unk> is a bit disjointed in this respect perhaps this is <unk> it is presented as a <unk> and making it too coherent would spoil the effect br br this movie is <unk> <unk> in more than one sense one never sees the sun shine grim but intriguing and frightening <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<unk> is the most original movie ive seen in years if you like unique thrillers that are influenced by film noir then this is just the right cure for all of those hollywood summer <unk> <unk> the theaters these days von <unk> <unk> like breaking the waves have gotten more <unk> but this is really his best work it is <unk> without being distracting and offers the perfect combination of suspense and dark humor its too bad he decided <unk> cameras were the wave of the future its hard to say who talked him away from the style he <unk> here but its everyones loss that he went into his heavily <unk> <unk> direction instead <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "<unk> von <unk> is never <unk> in trying out new techniques some of them are very original while others are best <unk> br he depicts <unk> germany as a <unk> train journey with so many cities lying in ruins <unk> <unk> a young american of german descent feels <unk> to help in their <unk> it is not a simple task as he quickly finds outbr br his uncle finds him a job as a night <unk> on the <unk> <unk> line his job is to <unk> to the needs of the passengers when the shoes are <unk> a <unk> mark is made on the <unk> a terrible argument <unk> when a passengers shoes are not <unk> despite the fact they have been <unk> there are many <unk> to the german <unk> of <unk> to such stupid <unk> br the <unk> journey is like an <unk> <unk> mans <unk> through life with all its <unk> and <unk> in one sequence <unk> <unk> through the back <unk> to discover them filled with <unk> bodies appearing to have just escaped from <unk> these images horrible as they are are <unk> as in a dream each with its own terrible impact yet <unk> br\n"
     ]
    }
   ],
   "source": [
    "# 读取数据归一化处理\r\n",
    "def create_padded_dataset(dataset):\r\n",
    "    padded_sents = []\r\n",
    "    labels = []\r\n",
    "    for batch_id, data in enumerate(dataset):\r\n",
    "        sent, label = data[0], data[1]\r\n",
    "        padded_sent = np.concatenate([sent[:seq_len], [pad_id] * (seq_len - len(sent))]).astype('int32')\r\n",
    "        padded_sents.append(padded_sent)\r\n",
    "        labels.append(label)\r\n",
    "    return np.array(padded_sents), np.array(labels)\r\n",
    "\r\n",
    "# 对train、test数据进行实例化\r\n",
    "train_sents, train_labels = create_padded_dataset(train_dataset)\r\n",
    "test_sents, test_labels = create_padded_dataset(test_dataset)\r\n",
    "\r\n",
    "# 查看数据大小及举例内容\r\n",
    "print(train_sents.shape)\r\n",
    "print(train_labels.shape)\r\n",
    "print(test_sents.shape)\r\n",
    "print(test_labels.shape)\r\n",
    "\r\n",
    "for sent in train_sents[:3]:\r\n",
    "    print(ids_to_str(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-19T06:26:56.332591Z",
     "iopub.status.busy": "2022-07-19T06:26:56.331107Z",
     "iopub.status.idle": "2022-07-19T06:26:56.344310Z",
     "shell.execute_reply": "2022-07-19T06:26:56.343123Z",
     "shell.execute_reply.started": "2022-07-19T06:26:56.332531Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IMDBDataset(paddle.io.Dataset):\r\n",
    "    '''\r\n",
    "    继承paddle.io.Dataset类进行封装数据\r\n",
    "    '''\r\n",
    "    def __init__(self, sents, labels):\r\n",
    "        self.sents = sents\r\n",
    "        self.labels = labels\r\n",
    "    \r\n",
    "    def __getitem__(self, index):\r\n",
    "        data = self.sents[index]\r\n",
    "        label = self.labels[index]\r\n",
    "\r\n",
    "        return data, label\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.sents)\r\n",
    "    \r\n",
    "train_dataset = IMDBDataset(train_sents, train_labels)\r\n",
    "test_dataset = IMDBDataset(test_sents, test_labels)\r\n",
    "\r\n",
    "train_loader = paddle.io.DataLoader(train_dataset, return_list=True,\r\n",
    "                                    shuffle=True, batch_size=batch_size, drop_last=True)\r\n",
    "test_loader = paddle.io.DataLoader(test_dataset, return_list=True,\r\n",
    "                                    shuffle=True, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下面与RNN不同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-19T06:29:00.605621Z",
     "iopub.status.busy": "2022-07-19T06:29:00.604481Z",
     "iopub.status.idle": "2022-07-19T06:29:00.614751Z",
     "shell.execute_reply": "2022-07-19T06:29:00.613723Z",
     "shell.execute_reply.started": "2022-07-19T06:29:00.605579Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import paddle.nn as nn\r\n",
    "import paddle\r\n",
    "\r\n",
    "# 定义RNN网络\r\n",
    "class MyRNN(paddle.nn.Layer):\r\n",
    "    def __init__(self):\r\n",
    "        super(MyRNN, self).__init__()\r\n",
    "        self.embedding = nn.Embedding(vocab_size, 256)\r\n",
    "        # self.rnn = nn.SimpleRNN(256, 256, num_layers=2, direction='forward',dropout=0.5)\r\n",
    "        self.gru=nn.GRU(256,256,num_layers=2,direction='bidirectional',dropout=0.5)\r\n",
    "        self.linear = nn.Linear(in_features=256*2, out_features=2)\r\n",
    "        self.dropout = nn.Dropout(0.5)\r\n",
    "    \r\n",
    "\r\n",
    "    def forward(self, inputs):\r\n",
    "        emb = self.dropout(self.embedding(inputs))\r\n",
    "        #output形状大小为[batch_size,seq_len,num_directions * hidden_size]\r\n",
    "        #hidden形状大小为[num_layers * num_directions, batch_size, hidden_size]\r\n",
    "        #把前向的hidden与后向的hidden合并在一起\r\n",
    "        output, hidden = self.gru(emb)\r\n",
    "        hidden = paddle.concat((hidden[-2,:,:], hidden[-1,:,:]), axis = 1)\r\n",
    "        #hidden形状大小为[batch_size, hidden_size * num_directions]\r\n",
    "        hidden = self.dropout(hidden)\r\n",
    "        return self.linear(hidden) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 上面与RNN不同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-19T06:29:02.919553Z",
     "iopub.status.busy": "2022-07-19T06:29:02.918276Z",
     "iopub.status.idle": "2022-07-19T06:29:02.925598Z",
     "shell.execute_reply": "2022-07-19T06:29:02.924588Z",
     "shell.execute_reply.started": "2022-07-19T06:29:02.919500Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 可视化定义\r\n",
    "def draw_process(title,color,iters,data,label):\r\n",
    "    plt.title(title, fontsize=24)\r\n",
    "    plt.xlabel(\"iter\", fontsize=20)\r\n",
    "    plt.ylabel(label, fontsize=20)\r\n",
    "    plt.plot(iters, data,color=color,label=label) \r\n",
    "    plt.legend()\r\n",
    "    plt.grid()\r\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-19T06:29:04.334863Z",
     "iopub.status.busy": "2022-07-19T06:29:04.334277Z",
     "iopub.status.idle": "2022-07-19T06:29:04.347981Z",
     "shell.execute_reply": "2022-07-19T06:29:04.347025Z",
     "shell.execute_reply.started": "2022-07-19T06:29:04.334823Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 对模型进行封装\r\n",
    "def train(model):\r\n",
    "    model.train()\r\n",
    "    opt = paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters())\r\n",
    "    steps = 0\r\n",
    "    Iters, total_loss, total_acc = [], [], []\r\n",
    "\r\n",
    "    for epoch in range(epochs):\r\n",
    "        for batch_id, data in enumerate(train_loader):\r\n",
    "            steps += 1\r\n",
    "            sent = data[0]\r\n",
    "            label = data[1]\r\n",
    "            \r\n",
    "            logits = model(sent)\r\n",
    "            loss = paddle.nn.functional.cross_entropy(logits, label)\r\n",
    "            acc = paddle.metric.accuracy(logits, label)\r\n",
    "\r\n",
    "            if batch_id % 500 == 0:  # 500个epoch输出一次结果\r\n",
    "                Iters.append(steps)\r\n",
    "                total_loss.append(loss.numpy()[0])\r\n",
    "                total_acc.append(acc.numpy()[0])\r\n",
    "\r\n",
    "                print(\"epoch: {}, batch_id: {}, loss is: {}\".format(epoch, batch_id, loss.numpy()))\r\n",
    "            \r\n",
    "            loss.backward()\r\n",
    "            opt.step()\r\n",
    "            opt.clear_grad()\r\n",
    "\r\n",
    "        # evaluate model after one epoch\r\n",
    "        model.eval()\r\n",
    "        accuracies = []\r\n",
    "        losses = []\r\n",
    "        \r\n",
    "        for batch_id, data in enumerate(test_loader):\r\n",
    "            \r\n",
    "            sent = data[0]\r\n",
    "            label = data[1]\r\n",
    "\r\n",
    "            logits = model(sent)\r\n",
    "            loss = paddle.nn.functional.cross_entropy(logits, label)\r\n",
    "            acc = paddle.metric.accuracy(logits, label)\r\n",
    "            \r\n",
    "            accuracies.append(acc.numpy())\r\n",
    "            losses.append(loss.numpy())\r\n",
    "        \r\n",
    "        avg_acc, avg_loss = np.mean(accuracies), np.mean(losses)\r\n",
    "\r\n",
    "        print(\"[validation] accuracy: {}, loss: {}\".format(avg_acc, avg_loss))\r\n",
    "        \r\n",
    "        model.train()\r\n",
    "\r\n",
    "        # 保存模型\r\n",
    "        paddle.save(model.state_dict(),str(epoch)+\"_model_final.pdparams\")\r\n",
    "    \r\n",
    "    # 可视化查看\r\n",
    "    draw_process(\"trainning loss\",\"red\",Iters,total_loss,\"trainning loss\")\r\n",
    "    draw_process(\"trainning acc\",\"green\",Iters,total_acc,\"trainning acc\")\r\n",
    "        \r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-19T06:29:07.017670Z",
     "iopub.status.busy": "2022-07-19T06:29:07.016459Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch_id: 0, loss is: [0.6882213]\n"
     ]
    }
   ],
   "source": [
    "epochs=150\r\n",
    "model = MyRNN()\r\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_state_dict=paddle.load('147_model_final.pdparams')\r\n",
    "model=MyRNN()\r\n",
    "model.set_state_dict(model_state_dict)\r\n",
    "model.eval()\r\n",
    "label_map={0:'negative',1:'positive'}\r\n",
    "eval_accs=[]\r\n",
    "eval_losses=[]\r\n",
    "samples=[]\r\n",
    "predictions=[]\r\n",
    "\r\n",
    "for batch_id,data in enumerate(test_loader):\r\n",
    "    x=data[0]\r\n",
    "    y=data[1]\r\n",
    "    pred=model(x)\r\n",
    "\r\n",
    "    for idx,probs in enumerate(pred):\r\n",
    "        prediction=label_map[np.argmax(probs)]\r\n",
    "        samples.append(x[idx].numpy())\r\n",
    "        predictions.append(prediction)\r\n",
    "\r\n",
    "    loss=paddle.nn.functional.cross_entropy(pred,y)\r\n",
    "    acc=paddle.metric.accuracy(pred,y)\r\n",
    "\r\n",
    "    eval_accs.append(acc.numpy()[0])\r\n",
    "    eval_losses.append(loss.numpy()[0])\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_acc,avg_loss=np.mean(eval_accs),np.mean(eval_losses)\r\n",
    "print(\"[validation] accuracy:{},loss:{}\".format(avg_acc,avg_loss))\r\n",
    "ind=0\r\n",
    "print('数据:{}\\n 情感:{}'.format(ids_to_str(samples[ind]),predictions[ind]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
