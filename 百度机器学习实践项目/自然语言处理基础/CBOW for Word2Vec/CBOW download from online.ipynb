{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T07:18:04.830480Z",
     "iopub.status.busy": "2022-07-13T07:18:04.829753Z",
     "iopub.status.idle": "2022-07-13T07:18:06.273220Z",
     "shell.execute_reply": "2022-07-13T07:18:06.272315Z",
     "shell.execute_reply.started": "2022-07-13T07:18:04.830439Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\r\n",
    "import random\r\n",
    "import io \r\n",
    "import sys \r\n",
    "import requests\r\n",
    "from collections import OrderedDict \r\n",
    "import math \r\n",
    "import numpy as np \r\n",
    "import paddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T07:18:11.610170Z",
     "iopub.status.busy": "2022-07-13T07:18:11.609595Z",
     "iopub.status.idle": "2022-07-13T07:18:11.614958Z",
     "shell.execute_reply": "2022-07-13T07:18:11.614031Z",
     "shell.execute_reply.started": "2022-07-13T07:18:11.610128Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def download():\r\n",
    "    corpus_url='https://dataset.bj.bcebos.com/word2vec/text8.txt'\r\n",
    "    web_requests=requests.get(corpus_url)\r\n",
    "    corpus=web_requests.content\r\n",
    "    with open('./text8.txt','wb') as f:\r\n",
    "        f.write(corpus)\r\n",
    "        f.close()\r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T07:18:20.359253Z",
     "iopub.status.busy": "2022-07-13T07:18:20.358259Z",
     "iopub.status.idle": "2022-07-13T07:18:24.360974Z",
     "shell.execute_reply": "2022-07-13T07:18:24.360013Z",
     "shell.execute_reply.started": "2022-07-13T07:18:20.359215Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T07:18:39.473687Z",
     "iopub.status.busy": "2022-07-13T07:18:39.472679Z",
     "iopub.status.idle": "2022-07-13T07:18:39.477783Z",
     "shell.execute_reply": "2022-07-13T07:18:39.476813Z",
     "shell.execute_reply.started": "2022-07-13T07:18:39.473646Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_text8():\r\n",
    "    with open('./text8.txt') as f:\r\n",
    "        corpus=f.read().strip('\\n')\r\n",
    "        f.close()\r\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T07:18:47.452085Z",
     "iopub.status.busy": "2022-07-13T07:18:47.451050Z",
     "iopub.status.idle": "2022-07-13T07:18:47.661643Z",
     "shell.execute_reply": "2022-07-13T07:18:47.660448Z",
     "shell.execute_reply.started": "2022-07-13T07:18:47.452043Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus=load_text8()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T07:18:53.709946Z",
     "iopub.status.busy": "2022-07-13T07:18:53.709388Z",
     "iopub.status.idle": "2022-07-13T07:18:53.720807Z",
     "shell.execute_reply": "2022-07-13T07:18:53.719753Z",
     "shell.execute_reply.started": "2022-07-13T07:18:53.709906Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' anarchism originated as a term of abuse first used against early working class radicals including the diggers of the english revolution and the sans culottes of the french revolution whilst the term is still used in a pejorative way to describe any act that used violent means to destroy the organization of society it has also been taken up as a positive label by self defined anarchists the word anarchism is derived from the greek without archons ruler chief king anarchism as a political philoso'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T07:19:11.811263Z",
     "iopub.status.busy": "2022-07-13T07:19:11.810505Z",
     "iopub.status.idle": "2022-07-13T07:19:11.815233Z",
     "shell.execute_reply": "2022-07-13T07:19:11.814528Z",
     "shell.execute_reply.started": "2022-07-13T07:19:11.811226Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def data_preprocess(corpus):\r\n",
    "    corpus=corpus.strip().lower()\r\n",
    "    corpus=corpus.split(' ')\r\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T07:19:19.723109Z",
     "iopub.status.busy": "2022-07-13T07:19:19.722516Z",
     "iopub.status.idle": "2022-07-13T07:19:21.129718Z",
     "shell.execute_reply": "2022-07-13T07:19:21.128713Z",
     "shell.execute_reply.started": "2022-07-13T07:19:19.723067Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus=data_preprocess(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T07:19:28.232469Z",
     "iopub.status.busy": "2022-07-13T07:19:28.231567Z",
     "iopub.status.idle": "2022-07-13T07:19:28.237930Z",
     "shell.execute_reply": "2022-07-13T07:19:28.237189Z",
     "shell.execute_reply.started": "2022-07-13T07:19:28.232409Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anarchism',\n",
       " 'originated',\n",
       " 'as',\n",
       " 'a',\n",
       " 'term',\n",
       " 'of',\n",
       " 'abuse',\n",
       " 'first',\n",
       " 'used',\n",
       " 'against',\n",
       " 'early',\n",
       " 'working',\n",
       " 'class',\n",
       " 'radicals',\n",
       " 'including',\n",
       " 'the',\n",
       " 'diggers',\n",
       " 'of',\n",
       " 'the',\n",
       " 'english',\n",
       " 'revolution',\n",
       " 'and',\n",
       " 'the',\n",
       " 'sans',\n",
       " 'culottes',\n",
       " 'of',\n",
       " 'the',\n",
       " 'french',\n",
       " 'revolution',\n",
       " 'whilst',\n",
       " 'the',\n",
       " 'term',\n",
       " 'is',\n",
       " 'still',\n",
       " 'used',\n",
       " 'in',\n",
       " 'a',\n",
       " 'pejorative',\n",
       " 'way',\n",
       " 'to',\n",
       " 'describe',\n",
       " 'any',\n",
       " 'act',\n",
       " 'that',\n",
       " 'used',\n",
       " 'violent',\n",
       " 'means',\n",
       " 'to',\n",
       " 'destroy',\n",
       " 'the']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T07:19:54.669834Z",
     "iopub.status.busy": "2022-07-13T07:19:54.669197Z",
     "iopub.status.idle": "2022-07-13T07:19:55.210557Z",
     "shell.execute_reply": "2022-07-13T07:19:55.209471Z",
     "shell.execute_reply.started": "2022-07-13T07:19:54.669791Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_dict(corpus):\r\n",
    "    word_freq_dict={}\r\n",
    "    for word in corpus:\r\n",
    "        if word not in word_freq_dict:\r\n",
    "            word_freq_dict[word]=0\r\n",
    "        word_freq_dict[word]+=1\r\n",
    "    \r\n",
    "    word_freq_dict=sorted(word_freq_dict.items(),key=lambda x:x[1],reverse=True)\r\n",
    "    \r\n",
    "    word2id={}\r\n",
    "    id2freq={}\r\n",
    "    id2word={}\r\n",
    "    \r\n",
    "    for word,freq in word_freq_dict:\r\n",
    "        ind=len(word2id)\r\n",
    "        word2id[word]=ind\r\n",
    "        id2freq[ind]=freq\r\n",
    "        id2word[ind]=word\r\n",
    "    \r\n",
    "    return id2freq,word2id,id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T07:20:03.437734Z",
     "iopub.status.busy": "2022-07-13T07:20:03.437388Z",
     "iopub.status.idle": "2022-07-13T07:20:08.057991Z",
     "shell.execute_reply": "2022-07-13T07:20:08.057065Z",
     "shell.execute_reply.started": "2022-07-13T07:20:03.437706Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "id2freq,word2id,id2word=build_dict(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T07:20:10.864667Z",
     "iopub.status.busy": "2022-07-13T07:20:10.864098Z",
     "iopub.status.idle": "2022-07-13T07:20:10.868341Z",
     "shell.execute_reply": "2022-07-13T07:20:10.867602Z",
     "shell.execute_reply.started": "2022-07-13T07:20:10.864628Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocab_size=len(id2freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T07:20:17.479082Z",
     "iopub.status.busy": "2022-07-13T07:20:17.478483Z",
     "iopub.status.idle": "2022-07-13T07:20:17.483793Z",
     "shell.execute_reply": "2022-07-13T07:20:17.483135Z",
     "shell.execute_reply.started": "2022-07-13T07:20:17.479039Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253854"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T07:20:25.219566Z",
     "iopub.status.busy": "2022-07-13T07:20:25.218941Z",
     "iopub.status.idle": "2022-07-13T07:20:25.225389Z",
     "shell.execute_reply": "2022-07-13T07:20:25.224607Z",
     "shell.execute_reply.started": "2022-07-13T07:20:25.219505Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word:the,its id:0,its freq:1061396\n",
      "word:of,its id:1,its freq:593677\n",
      "word:and,its id:2,its freq:416629\n",
      "word:one,its id:3,its freq:411764\n",
      "word:in,its id:4,its freq:372201\n",
      "word:a,its id:5,its freq:325873\n",
      "word:to,its id:6,its freq:316376\n",
      "word:zero,its id:7,its freq:264975\n"
     ]
    }
   ],
   "source": [
    "for _,(word,word_id) in zip(range(8),word2id.items()):\r\n",
    "    print(f'word:{word},its id:{word_id},its freq:{id2freq[word_id]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 转化为id序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T07:20:33.771231Z",
     "iopub.status.busy": "2022-07-13T07:20:33.770791Z",
     "iopub.status.idle": "2022-07-13T07:20:36.454215Z",
     "shell.execute_reply": "2022-07-13T07:20:36.453269Z",
     "shell.execute_reply.started": "2022-07-13T07:20:33.771185Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus=[word2id[word] for word in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T07:20:59.489295Z",
     "iopub.status.busy": "2022-07-13T07:20:59.488717Z",
     "iopub.status.idle": "2022-07-13T07:20:59.495229Z",
     "shell.execute_reply": "2022-07-13T07:20:59.494508Z",
     "shell.execute_reply.started": "2022-07-13T07:20:59.489255Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5233, 3080, 11, 5, 194, 1, 3133, 45]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二次采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T07:21:19.817163Z",
     "iopub.status.busy": "2022-07-13T07:21:19.816558Z",
     "iopub.status.idle": "2022-07-13T07:21:19.821328Z",
     "shell.execute_reply": "2022-07-13T07:21:19.820688Z",
     "shell.execute_reply.started": "2022-07-13T07:21:19.817135Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def subsampling(corpus,id2freq):\r\n",
    "    \r\n",
    "    def discard(word_id):\r\n",
    "        q=1-math.sqrt(1e-4/id2freq[word_id]*len(corpus))\r\n",
    "        return random.uniform(0,1)<q\r\n",
    "    corpus=[word for word in corpus if not discard(word)]\r\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T07:21:27.935430Z",
     "iopub.status.busy": "2022-07-13T07:21:27.934337Z",
     "iopub.status.idle": "2022-07-13T07:21:38.309740Z",
     "shell.execute_reply": "2022-07-13T07:21:38.308861Z",
     "shell.execute_reply.started": "2022-07-13T07:21:27.935390Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8742118\n",
      "[5233, 3080, 11, 5, 3133, 45, 155, 741]\n"
     ]
    }
   ],
   "source": [
    "corpus=subsampling(corpus,id2freq)\r\n",
    "print(len(corpus))\r\n",
    "print(corpus[:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T07:21:47.240168Z",
     "iopub.status.busy": "2022-07-13T07:21:47.239546Z",
     "iopub.status.idle": "2022-07-13T07:21:47.247982Z",
     "shell.execute_reply": "2022-07-13T07:21:47.247234Z",
     "shell.execute_reply.started": "2022-07-13T07:21:47.240125Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_data(corpus,word2id,id2freq,max_window_size=3,negative_sample_num=4):\r\n",
    "    dataset=[]\r\n",
    "    center_word_idx=0\r\n",
    "    \r\n",
    "    while center_word_idx<len(corpus):\r\n",
    "        window_size=random.randint(1,max_window_size)\r\n",
    "        positive_word=corpus[center_word_idx]\r\n",
    "        \r\n",
    "        context_word_range=(max(0,center_word_idx-window_size),min(len(corpus)-1,center_word_idx+window_size))\r\n",
    "        context_word_candidates=[corpus[idx] for idx in range(context_word_range[0],context_word_range[1]+1) if idx!=center_word_idx]\r\n",
    "        \r\n",
    "        for context_word in context_word_candidates:\r\n",
    "            dataset.append((context_word,positive_word,1))\r\n",
    "            i=0\r\n",
    "            while i<negative_sample_num:\r\n",
    "                negative_word_candidate=random.randint(0,vocab_size-1)\r\n",
    "                if negative_word_candidate is not positive_word:\r\n",
    "                    dataset.append((context_word,negative_word_candidate,0))\r\n",
    "                    i+=1\r\n",
    "        \r\n",
    "        center_word_idx=min(len(corpus)-1,center_word_idx+window_size)\r\n",
    "        if center_word_idx==(len(corpus)-1):\r\n",
    "            center_word_idx+=1\r\n",
    "        if(center_word_idx%100000==0):\r\n",
    "            print(center_word_idx)\r\n",
    "    return dataset\r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T07:22:20.153961Z",
     "iopub.status.busy": "2022-07-13T07:22:20.153207Z",
     "iopub.status.idle": "2022-07-13T07:24:05.732091Z",
     "shell.execute_reply": "2022-07-13T07:24:05.731148Z",
     "shell.execute_reply.started": "2022-07-13T07:22:20.153918Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "500000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1900000\n",
      "2100000\n",
      "2200000\n",
      "2300000\n",
      "2400000\n",
      "2500000\n",
      "2800000\n",
      "2900000\n",
      "3000000\n",
      "3300000\n",
      "3500000\n",
      "3600000\n",
      "3800000\n",
      "4100000\n",
      "4200000\n",
      "4400000\n",
      "4500000\n",
      "4800000\n",
      "5000000\n",
      "5200000\n",
      "5300000\n",
      "5700000\n",
      "5900000\n",
      "6000000\n",
      "6100000\n",
      "6200000\n",
      "6500000\n",
      "6600000\n",
      "6800000\n",
      "6900000\n",
      "7000000\n",
      "7100000\n",
      "7200000\n",
      "7300000\n",
      "7400000\n",
      "7600000\n",
      "8100000\n",
      "8200000\n",
      "8300000\n",
      "8400000\n",
      "8600000\n"
     ]
    }
   ],
   "source": [
    "dataset=build_data(corpus,word2id,id2freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T07:24:24.329018Z",
     "iopub.status.busy": "2022-07-13T07:24:24.328017Z",
     "iopub.status.idle": "2022-07-13T07:24:24.334314Z",
     "shell.execute_reply": "2022-07-13T07:24:24.333573Z",
     "shell.execute_reply.started": "2022-07-13T07:24:24.328980Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3080, 5233, 1)\n",
      "(3080, 100002, 0)\n",
      "(3080, 2511, 0)\n",
      "(3080, 177568, 0)\n",
      "(3080, 62173, 0)\n",
      "(11, 5233, 1)\n",
      "(11, 12109, 0)\n",
      "(11, 232036, 0)\n",
      "(11, 30446, 0)\n",
      "(11, 168882, 0)\n",
      "(5, 5233, 1)\n"
     ]
    }
   ],
   "source": [
    "for _,data in zip(range(11),dataset):\r\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造数据生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T07:24:31.292950Z",
     "iopub.status.busy": "2022-07-13T07:24:31.292320Z",
     "iopub.status.idle": "2022-07-13T07:24:31.299572Z",
     "shell.execute_reply": "2022-07-13T07:24:31.298854Z",
     "shell.execute_reply.started": "2022-07-13T07:24:31.292910Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_batch(dataset,batch_size,epoch_num):\r\n",
    "    context_word_batch=[]\r\n",
    "    target_word_batch=[]\r\n",
    "    label_batch=[]\r\n",
    "    \r\n",
    "    for epoch in range(epoch_num):\r\n",
    "        random.shuffle(dataset)\r\n",
    "        for context_word,target_word,label in dataset:\r\n",
    "            context_word_batch.append([context_word])\r\n",
    "            target_word_batch.append([target_word])\r\n",
    "            label_batch.append(label)\r\n",
    "            \r\n",
    "            if len(context_word_batch)==batch_size:\r\n",
    "                yield np.array(context_word_batch).astype('int64'),\\\r\n",
    "                    np.array(target_word_batch).astype('int64'),\\\r\n",
    "                    np.array(label_batch).astype('float32')\r\n",
    "        \r\n",
    "        if len(context_word_batch)>0:\r\n",
    "            yield np.array(context_word_batch).astype('int64'),\\\r\n",
    "                np.array(target_word_batch).astype('int64'),\\\r\n",
    "                np.array(label_batch).astype('float32')\r\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T07:24:38.896677Z",
     "iopub.status.busy": "2022-07-13T07:24:38.895633Z",
     "iopub.status.idle": "2022-07-13T07:24:38.905388Z",
     "shell.execute_reply": "2022-07-13T07:24:38.904572Z",
     "shell.execute_reply.started": "2022-07-13T07:24:38.896634Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CBOW(paddle.nn.Layer):\r\n",
    "    def __init__(self,vocab_size,embedding_size,init_scale=0.1):\r\n",
    "        super(CBOW,self).__init__()\r\n",
    "        self.vocab_size=vocab_size\r\n",
    "        self.embedding_size=embedding_size\r\n",
    "        self.embedding=paddle.nn.Embedding(\r\n",
    "            self.vocab_size,\r\n",
    "            self.embedding_size,\r\n",
    "            weight_attr=paddle.ParamAttr(\r\n",
    "                name='embedding_para',\r\n",
    "                initializer=paddle.nn.initializer.Uniform(\r\n",
    "                    low=-0.5/embedding_size,high=0.5/embedding_size\r\n",
    "                )\r\n",
    "            )\r\n",
    "        )\r\n",
    "        \r\n",
    "        self.embedding_out=paddle.nn.Embedding(\r\n",
    "            self.vocab_size,\r\n",
    "            self.embedding_size,\r\n",
    "            weight_attr=paddle.ParamAttr(\r\n",
    "                name='embedding_out_para',\r\n",
    "                initializer=paddle.nn.initializer.Uniform(\r\n",
    "                    low=-0.5/embedding_size,high=0.5/embedding_size\r\n",
    "                )\r\n",
    "            )\r\n",
    "        )\r\n",
    "    \r\n",
    "    def forward(self,context_words,target_words,label):\r\n",
    "        context_words_emb=self.embedding(context_words)\r\n",
    "        target_words_emb=self.embedding_out(target_words)\r\n",
    "        word_sim=paddle.multiply(context_words_emb,target_words_emb)\r\n",
    "        word_sim=paddle.sum(word_sim,axis=-1)\r\n",
    "        word_sim=paddle.reshape(word_sim,shape=[-1])\r\n",
    "        pred=paddle.nn.functional.sigmoid(word_sim)\r\n",
    "        loss=paddle.nn.functional.binary_cross_entropy(pred,label)\r\n",
    "        print(f\"see loss:\\n{loss}\")\r\n",
    "        loss=paddle.mean(loss)\r\n",
    "        print(f\"see loss after mean:\\n{loss}\")\r\n",
    "        return pred,loss\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T07:24:42.805350Z",
     "iopub.status.busy": "2022-07-13T07:24:42.804497Z",
     "iopub.status.idle": "2022-07-13T07:24:42.811197Z",
     "shell.execute_reply": "2022-07-13T07:24:42.810054Z",
     "shell.execute_reply.started": "2022-07-13T07:24:42.805311Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size=512\r\n",
    "epoch_num=3\r\n",
    "embedding_size=200\r\n",
    "step=0\r\n",
    "learning_rate=0.001\r\n",
    "\r\n",
    "def get_cos(query1_token,query2_token,embed):\r\n",
    "    W=embed\r\n",
    "    x=W[word2id[query1_token]]\r\n",
    "    y=W[word2id[query2_token]]\r\n",
    "    cos=np.dot(x,y)/np.sqrt(np.sum(y*y)*np.sum(x*x)+1e-9)\r\n",
    "    flat=cos.flatten()\r\n",
    "    print(f\"{query1_token}和{query2_token}的cos结果为{cos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T07:24:44.266161Z",
     "iopub.status.busy": "2022-07-13T07:24:44.265148Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0713 15:24:44.271684   395 gpu_context.cc:278] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 10.1\n",
      "W0713 15:24:44.276151   395 gpu_context.cc:306] device: 0, cuDNN Version: 7.6.\n"
     ]
    }
   ],
   "source": [
    "skip_gram_model=CBOW(vocab_size,embedding_size)\r\n",
    "adam=paddle.optimizer.Adam(learning_rate=learning_rate,parameters=skip_gram_model.parameters())\r\n",
    "\r\n",
    "for context_words,target_words,label in build_batch(dataset,batch_size,epoch_num):\r\n",
    "    context_word_var=paddle.to_tensor(context_words)\r\n",
    "    target_words_var=paddle.to_tensor(target_words)\r\n",
    "    label_var=paddle.to_tensor(label)\r\n",
    "    \r\n",
    "    print(f\"see target_words:\\n{target_words}\")\r\n",
    "    \r\n",
    "    pred,loss=skip_gram_model(context_words_var,target_words_var,label_var)\r\n",
    "    \r\n",
    "    loss.backward()\r\n",
    "    adam.minimize(loss)\r\n",
    "    skip_gram_model.clear_gradients()\r\n",
    "    \r\n",
    "    step+=1\r\n",
    "    if step%100==0:\r\n",
    "        print('step {step},loss {loss.numpy()[0]}')\r\n",
    "    \r\n",
    "    if step%2000==0:\r\n",
    "        embedding_matrix=skip_gram_model.embedding.weigth.numpy()\r\n",
    "        np.save('./embedding',embedding_matrix)\r\n",
    "        get_cos(\"king\",\"queen\",embedding_matrix)\r\n",
    "        get_cos('she','her',embedding_matrix)\r\n",
    "        get_cos('topic','theme',embedding_matrix)\r\n",
    "        get_cos('woman','game',embedding_matrix)\r\n",
    "        get_cos('one','name',embedding_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
